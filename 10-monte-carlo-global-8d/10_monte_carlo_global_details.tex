\subsection{10.8 – Lecture et préparation des échantillons Planck}
\begin{enumerate}
  \item Charger la chaîne MCMC Planck (\texttt{planck2018\_chain.csv}) contenant les colonnes \texttt{omegabh2}, \texttt{omegach2} et \texttt{H0}.
  \item Pour chaque ligne \(i\) :
    \[
      h_{i} = \frac{H_{0}^{(i)}}{100}, 
      \quad
      \Omega_{m}^{(i)} = \frac{\omega_{b}h^{2} + \omega_{c}h^{2}}{h^{2}},
      \quad
      H_{0}^{(i)} = H_{0}^{(i)}\;\text{(déjà en km/s/Mpc)}.
    \]
  \item Conserver ces paires \(\{\Omega_{m}^{(i)},\,H_{0}^{(i)}\}\) dans un tableau NumPy de taille \((N_{\rm Planck},\,2)\).
\end{enumerate}

\subsection{10.9 – Génération des tirages MCGT}
\begin{enumerate}
  \item Fixer la graine aléatoire :  
    \verb|np.random.seed(0)|  

  \item Définir les distributions normales :
    \begin{align*}
      \alpha_{1} &\sim \mathcal{N}(0.40,\,0.01^{2}), &
      T_{c} &\sim \mathcal{N}(0.25\,\mathrm{Gyr},\,0.01^{2}), \\
      \Delta &\sim \mathcal{N}(3.00,\,0.50^{2}), &
      T_{p} &\sim \mathcal{N}(0.05\,\mathrm{Gyr},\,0.01^{2}), \\
      \Delta_{p} &\sim \mathcal{N}(0.10\,\mathrm{Gyr},\,0.02^{2}), &
      \beta &\sim \mathcal{N}(5\times10^{-9},\,(2\times10^{-10})^{2}).
    \end{align*}

  \item Générer pour \(i=0,\dots,N_{\rm MC}-1\) (\(N_{\rm MC}=10^{5}\)) un échantillon MCGT :
    \[
      \alpha_{1}^{(i)},\,T_{c}^{(i)},\,\Delta^{(i)},\,T_{p}^{(i)},\,\Delta_{p}^{(i)},\,\beta^{(i)}.
    \]
    Conserver ces six valeurs dans un tableau \texttt{mcgt\_samples} de forme \((N_{\rm MC},\,6)\).
\end{enumerate}

\subsection{10.10 – Assemblage des vecteurs \(\Theta^{(i)}\)}
\begin{enumerate}
  \item Initialiser un tableau \texttt{samples} de forme \((N_{\rm MC},\,8)\).
  \item Pour chaque \(i=0,\dots,N_{\rm MC}-1\) :
    \begin{itemize}
      \item Sélectionner l’indice Planck \(j = i \bmod N_{\rm Planck}\).  
      \item Extraire \(\Omega_{m}^{(j)},\,H_{0}^{(j)}\) depuis le tableau Planck.  
      \item Affecter :
        \[
          \texttt{samples}[i,\,0:6] = \texttt{mcgt\_samples}[i,\,0:6], 
          \quad
          \texttt{samples}[i,\,6] = \Omega_{m}^{(j)}, 
          \quad
          \texttt{samples}[i,\,7] = H_{0}^{(j)}.
        \]
    \end{itemize}
  \item Au terme de la boucle, \texttt{samples[i]} contient 
    \(\bigl[\alpha_{1}^{(i)},\,T_{c}^{(i)},\,\Delta^{(i)},\,T_{p}^{(i)},\,\Delta_{p}^{(i)},\,\beta^{(i)},\,\Omega_{m}^{(j)},\,H_{0}^{(j)}\bigr]\).
\end{enumerate}

\subsection{10.11 – Calcul et sauvegarde de la covariance empirique}
\begin{enumerate}
  \item Appeler NumPy pour calculer la covariance :
    \[
      C_{8\times8} = \texttt{np.cov(samples, rowvar=False)}.
    \]
  \item Vérifier la symétrie :  
    \texttt{assert np.allclose(cov8, cov8.T)}  
  \item Vérifier que toutes les variances diagonales sont strictement positives :
    \texttt{assert np.all(np.diag(cov8) > 0)}  
  \item Sauvegarder au format binaire NumPy :
    \[
      \texttt{np.save('10\_global\_covariance\_real.npy',\,C_{8\times8})}.
    \]
\end{enumerate}

\subsection{10.12 – Script \texttt{plot\_covariance\_heatmap.py}}
\begin{verbatim}
import numpy as np
import matplotlib.pyplot as plt

# Chargement de la matrice
cov8 = np.load('10_global_covariance_real.npy')

# Paramètres pour l'affichage
vmax = np.max(np.abs(cov8))
labels = ['alpha1', 'Tc', 'Delta', 'Tp', 'Dp', 'beta', 'Omega_m', 'H0']

# Création de la figure
plt.figure(figsize=(8, 6))
plt.imshow(cov8, cmap='bwr', vmin=-vmax, vmax=vmax)
plt.colorbar(label='Covariance')

# Annotations dans chaque case
n = cov8.shape[0]
for i in range(n):
    for j in range(n):
        plt.text(j, i, f'{cov8[i, j]:.2e}', ha='center', va='center', fontsize=6)

# Étiquetage des axes
plt.xticks(range(n), labels, rotation=45, ha='right')
plt.yticks(range(n), labels)
plt.tight_layout()
plt.savefig('fig_01_covariance_heatmap.png', dpi=300)
plt.close()
\end{verbatim}

\subsection{10.13 – Script \texttt{plot\_covariance\_distributions.py}}
\begin{verbatim}
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import gaussian_kde

# Chargement des échantillons générés précédemment
samples = np.load('10_global_samples.npy')  # si enregistré, sinon recalculer samples

labels = ['alpha1', 'Tc', 'Delta', 'Tp', 'Dp', 'beta', 'Omega_m', 'H0']
n_params = samples.shape[1]

# Création d'une figure 2x4
fig, axes = plt.subplots(2, 4, figsize=(12, 6))
axes = axes.flatten()

for j in range(n_params):
    data_j = samples[:, j]
    kde = gaussian_kde(data_j)
    x_min, x_max = np.min(data_j), np.max(data_j)
    x_vals = np.linspace(x_min, x_max, 200)
    axes[j].plot(x_vals, kde(x_vals))
    sigma_j = np.std(data_j)
    axes[j].set_title(f'{labels[j]} (σ={sigma_j:.3f})')
    axes[j].set_xlabel(labels[j])
    axes[j].set_ylabel('Densité KDE')

plt.tight_layout()
plt.savefig('fig_02_distributions_unidimensionnelles.png', dpi=300)
plt.close()
\end{verbatim}

\subsection{10.14 – Script \texttt{plot\_covariance\_ellipse.py}}
\begin{verbatim}
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse

# Chargement de la matrice
cov8 = np.load('10_global_covariance_real.npy')

# Extraction de la sous-matrice pour (Omega_m, H0)
sub_cov = cov8[6:8, 6:8]
mean_planck = np.array([np.mean(samples[:, 6]), np.mean(samples[:, 7])])

# Calcul des ellipses de confiance
def ellipse_coords(cov_sub, mean, delta_chi2):
    vals, vecs = np.linalg.eigh(cov_sub * delta_chi2)
    order = vals.argsort()[::-1]
    vals, vecs = vals[order], vecs[:, order]
    width, height = 2 * np.sqrt(vals)
    angle = np.degrees(np.arctan2(vecs[1, 0], vecs[0, 0]))
    return width, height, angle

fig, ax = plt.subplots(figsize=(6, 6))
for delta_chi2, linestyle in [(2.30, 'solid'), (5.99, 'dashed')]:
    w, h, ang = ellipse_coords(sub_cov, mean_planck, delta_chi2)
    ellipse = Ellipse(xy=mean_planck, width=w, height=h, angle=ang,
                      edgecolor='black', fc='None', ls=linestyle, lw=1.5)
    ax.add_patch(ellipse)

ax.scatter(mean_planck[0], mean_planck[1], c='red', s=10)
ax.set_xlabel('Omega_m')
ax.set_ylabel('H0 (km/s/Mpc)')
ax.set_title('Ellipse de confiance pour (Omega_m, H0)')
ax.set_aspect('equal', 'box')
plt.tight_layout()
plt.savefig('fig_03_ellipse_Omega_m_H0.png', dpi=300)
plt.close()
\end{verbatim}

\subsection{10.15 – Dépendances et installation}
\begin{itemize}
  \item Python 3.8 ou supérieur  
  \item Packages :  
    \begin{itemize}
      \item \texttt{numpy} (manipulation de tableaux, calcul de covariance)  
      \item \texttt{scipy} (estimation KDE)  
      \item \texttt{matplotlib} (tracés)  
    \end{itemize}
  \item Installation recommandée :  
    \begin{verbatim}
    pip install numpy scipy matplotlib
    \end{verbatim}
\end{itemize}

\subsection{10.16 – Validations post‐calcul}
\begin{itemize}
  \item Vérifier la symétrie de la matrice :  
    \verb|assert np.allclose(cov8, cov8.T)|  
  \item Vérifier la positivité des variances :  
    \verb|assert np.all(np.diag(cov8) > 0)|  
  \item Contrôler que les écarts‐types reportés dans les KDE correspondent 
        à \(\sqrt{C_{jj}}\) pour chaque \(j\).  
  \item S’assurer que l’ellipse \((\Omega_{m},H_{0})\) est centrée sur 
        \(\bigl(\overline{\Omega}_{m},\,\overline{H}_{0}\bigr)\) 
        et reflète la corrélation de \(\text{sub_cov}\).
\end{itemize}

\bigskip
\noindent\emph{Fin de la partie détaillée, Chapitre 10.}